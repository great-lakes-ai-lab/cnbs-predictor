{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from properscoring import crps_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/Users/ljob/Desktop/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_observed_data(df):\n",
    "    # Melt the observed data to long format and create the 'year_month' column in a single step\n",
    "    observed_df = df.melt(id_vars=['Year'], var_name='Month', value_name='Observed')\n",
    "\n",
    "    # Combine 'Year' and 'Month' into a proper 'year_month' format and convert to datetime in one step\n",
    "    observed_df['year_month'] = (pd.to_datetime(observed_df['Year'].astype(str) + '-' + observed_df['Month'].str[1:4], format='%Y-%b')).dt.strftime('%Y-%m')\n",
    "    \n",
    "    # Sort by 'year_month' for proper chronological order\n",
    "    observed_df = observed_df.sort_values(by='year_month')\n",
    "    observed_df = observed_df[['year_month', 'Observed']].reset_index(drop=True)\n",
    "\n",
    "    return observed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_forecast_data(df):\n",
    "    # Step 1: Combine 'year' and 'month' into a datetime column 'first_month'\n",
    "    df['forecast_date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str), format='%Y-%m')\n",
    "\n",
    "    # Step 2: Melt the DataFrame\n",
    "    melted_df = pd.melt(df, id_vars=['forecast_date'], value_vars=['one', 'two', 'three', 'four', 'five', 'six'], \n",
    "                    var_name='month', value_name='nbs')\n",
    "    \n",
    "    # Step 3: Define the forecast month mapping\n",
    "    forecast_map = {\n",
    "        'one': 0,\n",
    "        'two': 1,\n",
    "        'three': 2,\n",
    "        'four': 3,\n",
    "        'five': 4,\n",
    "        'six': 5\n",
    "    }\n",
    "\n",
    "    melted_df['year_month'] = melted_df['forecast_date'] + melted_df['month'].map(forecast_map).apply(lambda x: pd.DateOffset(months=x))\n",
    "\n",
    "    melted_df['year_month'] = pd.to_datetime(melted_df['year_month']).dt.strftime('%Y-%m')\n",
    "\n",
    "    final_df = melted_df[['forecast_date', 'year_month', 'nbs']].sort_values(by=['forecast_date', 'year_month']).reset_index(drop=True)\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_skill_metrics(predictions, observations):\n",
    "\n",
    "    # Standardizing the observed and predicted values\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit and transform the data\n",
    "    pred_scaled = scaler.fit_transform(predictions.values.reshape(-1, 1))\n",
    "    obs_scaled = scaler.fit_transform(observations.values.reshape(-1, 1))\n",
    "\n",
    "    # RMSE (Root Mean Squared Error) on standardized data\n",
    "    rmse = np.sqrt(mean_squared_error(obs_scaled, pred_scaled))\n",
    "    print(f\"RMSE (Standardized): {rmse}\")\n",
    "\n",
    "    # R-squared on standardized data\n",
    "    r_squared = r2_score(obs_scaled, pred_scaled)\n",
    "    print(f\"R-squared (Standardized): {r_squared}\")\n",
    "\n",
    "    # Bias (Average of prediction - observation) on standardized data\n",
    "    bias = np.mean(pred_scaled - obs_scaled)\n",
    "    print(f\"Bias (Standardized): {bias}\")\n",
    "\n",
    "    # Variance (Variance of predictions) on standardized data\n",
    "    variance = np.var(pred_scaled)\n",
    "    print(f\"Variance (Standardized): {variance}\")\n",
    "\n",
    "    # CRPS (Continuous Ranked Probability Score)\n",
    "    # Assuming predicted is a deterministic point forecast (not distribution)\n",
    "    # CRPS is more meaningful for probabilistic forecasts. Here we use `crps_ensemble`\n",
    "    # For simplicity, we use the predicted as the ensemble of one prediction (as a proxy).\n",
    "    crps = crps_ensemble(obs_scaled, pred_scaled)\n",
    "    print(f\"CRPS (Standardized): {np.mean(crps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the observed data\n",
    "observed_sup = pd.read_csv(dir + 'GLCC/LakeSuperior_MonthlyNetBasinSupply_1900to2025.csv', skiprows=11)\n",
    "observed_mih = pd.read_csv(dir + 'GLCC/LakeMichiganHuron_MonthlyNetBasinSupply_1900to2025.csv', skiprows=11)\n",
    "observed_eri = pd.read_csv(dir + 'GLCC/LakeErie_MonthlyNetBasinSupply_1900to2025.csv', skiprows=11)\n",
    "observed_ont = pd.read_csv(dir + 'GLCC/LakeOntario_MonthlyNetBasinSupply_1900to2025.csv', skiprows=11)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obs_sup = format_observed_data(observed_sup)\n",
    "df_obs_mih = format_observed_data(observed_mih)\n",
    "df_obs_eri = format_observed_data(observed_eri)\n",
    "df_obs_ont = format_observed_data(observed_ont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load forecast data\n",
    "glshfs_sup = pd.read_csv(dir + 'NBS_LF/GLSHFSModel/SUP.GLSHFS.csv', skiprows=10)\n",
    "glshfs_mih = pd.read_csv(dir + 'NBS_LF/GLSHFSModel/MIH.GLSHFS.csv', skiprows=10)\n",
    "glshfs_eri = pd.read_csv(dir + 'NBS_LF/GLSHFSModel/ERI.GLSHFS.csv', skiprows=10)\n",
    "glshfs_ont = pd.read_csv(dir + 'NBS_LF/GLSHFSModel/ONT.GLSHFS.csv', skiprows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/ddc7n0594ydfswtzw_mmfs6c0000gp/T/ipykernel_95980/3507833474.py:19: PerformanceWarning: Adding/subtracting object-dtype array to DatetimeArray not vectorized.\n",
      "  melted_df['year_month'] = melted_df['forecast_date'] + melted_df['month'].map(forecast_map).apply(lambda x: pd.DateOffset(months=x))\n",
      "/var/folders/2w/ddc7n0594ydfswtzw_mmfs6c0000gp/T/ipykernel_95980/3507833474.py:19: PerformanceWarning: Adding/subtracting object-dtype array to DatetimeArray not vectorized.\n",
      "  melted_df['year_month'] = melted_df['forecast_date'] + melted_df['month'].map(forecast_map).apply(lambda x: pd.DateOffset(months=x))\n",
      "/var/folders/2w/ddc7n0594ydfswtzw_mmfs6c0000gp/T/ipykernel_95980/3507833474.py:19: PerformanceWarning: Adding/subtracting object-dtype array to DatetimeArray not vectorized.\n",
      "  melted_df['year_month'] = melted_df['forecast_date'] + melted_df['month'].map(forecast_map).apply(lambda x: pd.DateOffset(months=x))\n",
      "/var/folders/2w/ddc7n0594ydfswtzw_mmfs6c0000gp/T/ipykernel_95980/3507833474.py:19: PerformanceWarning: Adding/subtracting object-dtype array to DatetimeArray not vectorized.\n",
      "  melted_df['year_month'] = melted_df['forecast_date'] + melted_df['month'].map(forecast_map).apply(lambda x: pd.DateOffset(months=x))\n"
     ]
    }
   ],
   "source": [
    "df_glshfs_sup = format_forecast_data(glshfs_sup)\n",
    "df_glshfs_mih = format_forecast_data(glshfs_mih)\n",
    "df_glshfs_eri = format_forecast_data(glshfs_eri)\n",
    "df_glshfs_ont = format_forecast_data(glshfs_ont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge forecast and observations\n",
    "df_merged_sup = pd.merge(df_glshfs_sup, df_obs_sup, on='year_month', how='left')\n",
    "df_merged_mih = pd.merge(df_glshfs_mih, df_obs_mih, on='year_month', how='left')\n",
    "df_merged_eri = pd.merge(df_glshfs_eri, df_obs_eri, on='year_month', how='left')\n",
    "df_merged_ont = pd.merge(df_glshfs_ont, df_obs_ont, on='year_month', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any missing data in the observations\n",
    "df_merged_sup.replace(-99990.0, np.nan, inplace=True)\n",
    "df_merged_sup = df_merged_sup.dropna()\n",
    "\n",
    "df_merged_mih.replace(-99990.0, np.nan, inplace=True)\n",
    "df_merged_mih = df_merged_mih.dropna()\n",
    "\n",
    "df_merged_eri.replace(-99990.0, np.nan, inplace=True)\n",
    "df_merged_eri = df_merged_eri.dropna()\n",
    "\n",
    "df_merged_ont.replace(-99990.0, np.nan, inplace=True)\n",
    "df_merged_ont = df_merged_ont.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    forecast_date year_month   nbs  Observed\n",
      "0      2021-01-01    2021-01  -974    -650.0\n",
      "1      2021-01-01    2021-02  -393     260.0\n",
      "2      2021-01-01    2021-03  1370    1960.0\n",
      "3      2021-01-01    2021-04  2769    3800.0\n",
      "4      2021-01-01    2021-05  4241    2760.0\n",
      "..            ...        ...   ...       ...\n",
      "283    2024-12-01    2025-01 -1364    -760.0\n",
      "284    2024-12-01    2025-02  -739    -460.0\n",
      "288    2025-01-01    2025-01 -1185    -760.0\n",
      "289    2025-01-01    2025-02  -748    -460.0\n",
      "294    2025-02-01    2025-02  -604    -460.0\n",
      "\n",
      "[285 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_merged_sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the 4 dataframes into one long dataframe\n",
    "combined_df = pd.concat([df_merged_sup, df_merged_mih, df_merged_eri, df_merged_ont], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Standardized): 0.6432531574837181\n",
      "R-squared (Standardized): 0.5862253753872269\n",
      "Bias (Standardized): -1.246566203087895e-16\n",
      "Variance (Standardized): 0.9999999999999998\n",
      "CRPS (Standardized): 0.4723780650560114\n"
     ]
    }
   ],
   "source": [
    "calc_skill_metrics(combined_df['nbs'], combined_df['Observed'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
